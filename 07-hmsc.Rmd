---
title: "HMSC analysis"
author: "Claudia Romeo & Antton Alberdi"
date: "2024sc-01-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries

```{r libraries, warning=FALSE, comments="", message=FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(phyloseq))
suppressPackageStartupMessages(library(Hmsc))
suppressPackageStartupMessages(library(distillR))
suppressPackageStartupMessages(library(ggplot2))
```

## Load data

```{r load_data}
load("data/data.Rdata")
```

## Prepare input for Hmsc

Only using faecal samples.

```{r hmsc_input, warning=FALSE, comments="", message=FALSE}
# Random effects data (study design)
StudyDesign <- sample_metadata %>%
                    select(sample,animal,macroarea) %>%
                    mutate(macroarea = factor(macroarea)) %>%
                    mutate(animal = factor(animal)) %>%
                    column_to_rownames("sample")

# Genome count table (quantitative community data)
YData <- read_counts  %>%
                    mutate(across(where(is.numeric), ~ . +1 )) %>% #add +1 pseudocount to remove zeros
                    mutate(across(where(is.numeric), ~ . / (genome_metadata$length / 150) )) %>% #transform to genome counts
                    mutate(across(where(is.numeric), ~  log(.) )) %>% #log-transform
                    column_to_rownames("genome") %>%
                    select(all_of(row.names(StudyDesign))) %>%  #filter only faecal samples
                    as.data.frame() %>%
                    t() # transpose

# Fixed effects data (explanatory variables)
XData <- sample_metadata %>%
                    select(sample,species,area_type,season) %>%
                    mutate(logseqdepth=read_counts %>% #total log-sequencing depth
                        select(all_of(row.names(StudyDesign))) %>%
                        colSums() %>%
                        log()
                    ) %>%
                    mutate(species = factor(species)) %>%
                    mutate(area_type = factor(area_type)) %>%
                    mutate(season = factor(season)) %>%
                    column_to_rownames("sample")


# Genome trait data
TrData <- genome_gifts %>%
                    arrange(match(genome, colnames(YData))) %>%
                    column_to_rownames(var="genome") %>%
                    to.functions(.,GIFT_db) %>%
                    as.data.frame()

# Genome phylogeny
PData <- genome_tree
```

## Define formulas of the Hmsc model

```{r hmsc_formulas, warning=FALSE, comments="", message=FALSE}

# Fixed effects formula
XFormula = ~species*area_type + species*season + logseqdepth

# Trait formula
TrFormula = ~B01+B02+B03+B04+B07+D01+D02+D03+D05+D06+D07

# Study design
rL.animal = HmscRandomLevel(units = levels(StudyDesign$animal))
rL.macroarea = HmscRandomLevel(units = levels(StudyDesign$macroarea))
```

## Define and Hmsc models
```{r hmsc_models, warning=FALSE, comments="", message=FALSE}
#Define models
model1 = Hmsc(Y=YData,
         XData = XData,
         XFormula = XFormula,
         studyDesign = StudyDesign,
         phyloTree = PData,
         ranLevels = list("animal"=rL.animal, "macroarea"=rL.macroarea),
         TrData = TrData,
         TrFormula = TrFormula,
         distr = "normal",
         YScale = TRUE)

#Save list of models as an R object.
model_list = list(model1=model1)
if (!dir.exists("hmsc")){dir.create("hmsc")}
save(model_list, file = "hmsc/hmsc.Rdata")
```


Upload **hmsc/hmsc.Rdata** to the HPC respecting the directory structure.

## Define MCMC
```{r hmsc_mcmc, warning=FALSE, comments="", message=FALSE}
# How often to sample the MCMC
MCMC_samples_list = 250

# The number of MCMC steps between each recording sample
MCMC_thin_list = c(1, 10)

# The number of MCMC chains to use
nChains = 4
```


## Generate Hmsc executables

The next chunk generates shell files for every combination of model, MCMC samples and MCMM thinning, ready to be launched as SLURM jobs.

```{r hmsc_executables, warning=FALSE, comments="", message=FALSE}

modelchains <- expand.grid(model = names(model_list), sample = MCMC_samples_list, thin = MCMC_thin_list)

if (!dir.exists("hmsc")){dir.create("hmsc")}
for(i in c(1:nrow(modelchains))){
      modelname=as.character(modelchains[i,1])
      sample=modelchains[i,2]
      thin=modelchains[i,3]
      executablename <- paste0("hmsc/exe_",modelname,"_",sample,"_",thin,".sh")
      fitname <- paste0("hmsc/fit_",modelname,"_",sample,"_",thin,".Rdata")
      convname <- paste0("hmsc/conv_",modelname,"_",sample,"_",thin,".Rdata")
      model <- paste0('model_list$',modelname)
      psrf.beta.name <-  paste0("psrf.beta.",modelname,"_",sample,"_",thin)
      psrf.gamma.name <-  paste0("psrf.gamma.",modelname,"_",sample,"_",thin)
      psrf.rho.name <-  paste0("psrf.rho.",modelname,"_",sample,"_",thin)
      jobname <- paste0("hmsc_",modelname,"_",sample,"_",thin)
      minutes <- round(sample * thin / 4, 0)
      code <- sprintf("#!/bin/bash
#SBATCH --job-name=%s                   # Job name
#SBATCH --nodes=1
#SBATCH --ntasks=4                      # Run on 4 CPUs
#SBATCH --mail-user=antton.alberdi@sund.ku.dk
#SBATCH --mem=250gb                      # Job memory request
#SBATCH --time=%d                       # In minutes

# Activate conda environment
module load mamba/1.3.1
source activate /maps/projects/mjolnir1/people/jpl786/AMAC001_fibre_trial/hmsc/hmsc_env

# Run R script
Rscript -e '
library(tidyverse)
library(Hmsc)
# Load formulas and data
load(\"hmsc/hmsc.Rdata\")

# Declare placeholders
modelname = \"%s\"
model = %s
fitname = \"%s\"
convname = \"%s\"
sample = %d
thin = %d
nchains = %d

# Run model fitting
m = sampleMcmc(hM = model,
         samples = sample,
         thin = thin,
         adaptNf=rep(ceiling(0.4*sample*thin),model$nr),
         transient = ceiling(0.5*sample*thin),
         nChains = nchains,
         nParallel = nchains)

# Assess chain convergence
mpost = convertToCodaObject(m,
      spNamesNumbers = c(T,F),
      covNamesNumbers = c(T,F),
      Beta = TRUE,
      Gamma = TRUE,
      V = FALSE,
      Sigma = FALSE,
      Rho = TRUE,
      Eta = FALSE,
      Lambda = FALSE,
      Alpha = FALSE,
      Omega = FALSE,
      Psi = FALSE,
      Delta = FALSE) # Convert to CODA object

# Fixed effects
assign(paste0(\"psrf.beta.\", modelname,\"_\",sample,\"_\",thin), gelman.diag(mpost$Beta,multivariate=FALSE)$psrf)

# Traits
assign(paste0(\"psrf.gamma.\", modelname,\"_\",sample,\"_\",thin), gelman.diag(mpost$Gamma,multivariate=FALSE)$psrf)

# Phylogeny
assign(paste0(\"psrf.rho.\", modelname,\"_\",sample,\"_\",thin), gelman.diag(mpost$Rho,multivariate=FALSE)$psrf)

# Write convergence data
save(%s, %s, %s, file=convname)

# Save model fit object
save(m, file=fitname)
'
", jobname, minutes, modelname, model, fitname, convname, sample, thin, nChains, psrf.beta.name, psrf.gamma.name, psrf.rho.name)
      writeLines(code, executablename)
    }
```

Upload the produced **hmsc/exe_XXXXX.sh** files to the HPC respecting the directory structure.

## Fit Hmsc models (in Mjolnir HPC)

Launch the SLURM jobs by using:

```{sh, eval=FALSE}
# Submit all .sh files in the hmsc folder
for jobfile in hmsc/exe_*.sh; do
    sbatch "$jobfile"
done

#Or launch them one by one only the ones you want to launch
sbatch hmsc/exe_model1_250_1.sh
sbatch hmsc/exe_model1_250_10.sh
sbatch hmsc/exe_model1_250_100.sh
sbatch hmsc/exe_model1_250_1000.sh
```
```

## Assess chain convergence

Convergence diagnostic values substantially above 1 indicate lack of convergence.
Values below 1.1 are considered good enough

```{r hmsc_convergence, warning=FALSE, comments="", message=FALSE}

# Load all conv file available in the hmsc folder
list.files(path = "hmsc", pattern = "^conv_", full.names = TRUE, include.dirs = TRUE) %>%
  lapply(.,load,.GlobalEnv)

# Create a merged psrf.beta (genome) plot
ls() %>%
        grep("^psrf\\.beta", ., value = TRUE) %>%
        map_dfr(~ {
         mat <- get(.x)
          data.frame(modelchain = .x, as.data.frame(mat, , stringsAsFactors = FALSE)) %>%
              rownames_to_column(var="parameter") %>%
              mutate(model = str_split(modelchain, "_") %>% map_chr(1) %>% gsub("psrf.beta.","",.)) %>%
              mutate(sample = str_split(modelchain, "_") %>% map_chr(2)) %>% #extract sample info from model name
              mutate(thin = str_split(modelchain, "_") %>% map_chr(3)) #extract thin info from model name
      }) %>%
      ggplot(.,aes(x=reorder(modelchain,-Point.est.,fun=function(x) {quantile(x, probs = 0.9)}),y=Point.est.)) +
        geom_violin(fill="#b8d9e3", color="#328da8") +
        geom_jitter(alpha=0.3,size=0.2, color="#a8babf") +
        stat_summary(fun=function(x) {quantile(x, probs = 0.9)}, geom="crossbar", width=0.2, color="orange") +
        geom_hline(yintercept=1.1, linetype="dashed", color = "red") +
        ylim(0.9,2)+
        labs(x="Model chains",y="Parameter estimates")+
        theme_classic()

# Create a merged psrf.gamma (trait) plot
ls() %>%
        grep("^psrf\\.gamma", ., value = TRUE) %>%
        map_dfr(~ {
         mat <- get(.x)
          data.frame(modelchain = .x, as.data.frame(mat, , stringsAsFactors = FALSE)) %>%
              rownames_to_column(var="parameter") %>%
              mutate(model = str_split(modelchain, "_") %>% map_chr(1) %>% gsub("psrf.gamma.","",.)) %>%
              mutate(sample = str_split(modelchain, "_") %>% map_chr(2)) %>% #extract sample info from model name
              mutate(thin = str_split(modelchain, "_") %>% map_chr(3)) #extract thin info from model name
      }) %>%
      ggplot(.,aes(x=reorder(modelchain,-Point.est.,fun=function(x) {quantile(x, probs = 0.9)}),y=Point.est.)) +
        geom_violin(fill="#b8d9e3", color="#328da8") +
        geom_jitter(alpha=0.3,size=0.2, color="#a8babf") +
        stat_summary(fun=function(x) {quantile(x, probs = 0.9)}, geom="crossbar", width=0.2, color="orange") +
        geom_hline(yintercept=1.1, linetype="dashed", color = "red") +
        ylim(0.9,2)+
        labs(x="Model chains",y="Parameter estimates")+
        theme_classic()


# Create a merged psrf.rho (phylogeny) plot
ls() %>%
        grep("^psrf\\.rho", ., value = TRUE) %>%
        map_dfr(~ {
         mat <- get(.x)
          data.frame(modelchain = .x, as.data.frame(mat, , stringsAsFactors = FALSE)) %>%
              rownames_to_column(var="parameter") %>%
              mutate(model = str_split(modelchain, "_") %>% map_chr(1) %>% gsub("psrf.beta.","",.)) %>%
              mutate(sample = str_split(modelchain, "_") %>% map_chr(2)) %>% #extract sample info from model name
              mutate(thin = str_split(modelchain, "_") %>% map_chr(3)) #extract thin info from model name
      }) %>%
      ggplot(.,aes(x=reorder(modelchain,-Point.est.,fun=function(x) {quantile(x, probs = 0.9)}),y=Point.est.)) +
        geom_violin(fill="#b8d9e3", color="#328da8") +
        geom_jitter(alpha=0.3,size=0.2, color="#a8babf") +
        stat_summary(fun=function(x) {quantile(x, probs = 0.9)}, geom="crossbar", width=0.2, color="orange") +
        geom_hline(yintercept=1.1, linetype="dashed", color = "red") +
        ylim(0.9,2)+
        labs(x="Model chains",y="Parameter estimates")+
        theme_classic()

```

## Compute variance partitioning

```{r hmsc_variancepart, warning=FALSE, comments="", message=FALSE}

# Select modelchain of interest
load("hmsc/fit_model1_250_10.Rdata")

varpart=computeVariancePartitioning(m)
plotVariancePartitioning(hM=m,VP=varpart)
```
